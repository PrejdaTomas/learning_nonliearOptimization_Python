{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkce pro sumu čtverců reziduí linearizovaného problému\n",
    "\n",
    "$E(k,q) =  \\sum_{n=1}^N ({y_n}_t - {y_n}_m)^2 = \\sum_{n=1}^N ({y_n}_t - (k·x_n + q))^2$\\\n",
    "t... theory\\\n",
    "m... measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parciální derivace funkce sumy čtverců reziduí dle k:\n",
    "\n",
    "\n",
    "$\\frac{\\partial {E(k,q)}}{\\partial{k}} =  \\frac{\\partial}{\\partial{k}} \\sum_{n=1}^N ({y_n}_t - {y_n}_m)^2 = \\sum_{n=1}^N  (\\frac{\\partial}{\\partial{k}} ({y_n}_t - (k·x_n + q))^2)$\n",
    "\\\n",
    ".\n",
    "\n",
    "$\\frac{\\partial {E(k,q)}}{\\partial{k}} =  \\sum_{n=1}^N (2·({y_n}_t - (k·x_n + q))·(-x_n)) $\n",
    "\\\n",
    ".\n",
    "\n",
    "$\\frac{\\partial {E(k,q)}}{\\partial{k}} =  \\sum_{n=1}^N (-2x_n·({y_n}_t - (k·x_n + q))) $\n",
    "\n",
    "\n",
    "\\\n",
    "\\\n",
    "\\\n",
    ".\n",
    "\n",
    "\n",
    "Parciální derivace funkce sumy čtverců reziduí dle q:\n",
    "\n",
    "\n",
    "$\\frac{\\partial {E(k,q)}}{\\partial{q}} =  \\frac{\\partial}{\\partial{q}} \\sum_{n=1}^N ({y_n}_t - {y_n}_m)^2 = \\sum_{n=1}^N  (\\frac{\\partial}{\\partial{q}} ({y_n}_t - (k·x_n + q))^2)$\n",
    "\\\n",
    ".\n",
    "\n",
    "$\\frac{\\partial {E(k,q)}}{\\partial{q}} =  \\sum_{n=1}^N (2·({y_n}_t - (k·x_n + q))·(-1) $\n",
    "\\\n",
    ".\n",
    "\n",
    "$\\frac{\\partial {E(k,q)}}{\\partial{q}} =  \\sum_{n=1}^N (-2·({y_n}_t - (k·x_n + q))) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parciální derivace položíme do rovnosti s 0 a mám systém rovnic.\\\n",
    "$  \\sum_{n=1}^N (-2x_n·({y_n}_t - (k·x_n + q))) = 0 $\n",
    "\n",
    "\n",
    "$  \\sum_{n=1}^N (-2·({y_n}_t - (k·x_n + q))) = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\\n",
    "\\\n",
    "\\ \n",
    "\n",
    "Ta funkce, jejíž sumu reziduí hledáme, nemusí být jen přímka, například polynom...\\\n",
    "$f(x; c_0, c_1, c_2, ...) =  \\sum_{n=1}^N c_n·x^n$ \\\n",
    "\n",
    "Středník zde ve funkci odděluje nezávislou proměnnou od koeficientů s libovolným množstvím.\\\n",
    "\n",
    "Podmínkou je tedy, že musíme být schopni oddělit neznámé parametry od datových bodů, aby se dala funkce vyjádřit jako lineární kombinace bázových funkcí dané nezávislé proměnné:\\\n",
    "$f(x; \\vec{c}) =  \\sum_{n=1}^N c_n·\\Phi_n(x)$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "\\\n",
    "\n",
    "Bázové funkce mohou mít:\n",
    "1) uzavřenou formu\n",
    "    $\\Phi_n(x) = x^n$\n",
    "    \n",
    "2) rekurzivní formu (Čebyševovy polynomy)\\\n",
    "    $\\Phi_n(x) = 2x\\Phi_{n-1}(x) - \\Phi_{n-2}(x)$\\\n",
    "    $x\\Phi_0(x) = 1$\\\n",
    "    $x\\Phi_1(x) = x$\n",
    "3) formy diskrétní sady funkcí (piecewise)\\\n",
    "    $\\Phi_{n}(x) = (x, sin(x))$ \\\n",
    "    $f(x; \\vec{c}) = c_0·x + c_1·sin(x)$ ... příklad toho, jak by taková poskládaná funkce vypadala\n",
    "\n",
    "\\\n",
    "\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Důvodem, proč jsme postavili tu fitovanou funkci takto je ten, že se její první derivace dají snadno definovat, což je důležité pro minimalizaci.\\\n",
    "$f(x; \\vec{c}) =  \\sum_{n=1}^N c_n·\\Phi_n(x)$ \n",
    "\n",
    "$\\frac{\\partial {f(x; \\vec{c})}}{\\partial{c_i}} =  \\sum_{n=1}^N \\frac{\\partial}{\\partial{k}} (c_n·\\Phi_n(x))  = \\Phi_i(x)$ \\\n",
    "Je to docela hardcore, protože veškerá suma zmizí. Je to z toho důvodu, vše derivace všech koeficientů všemi koeficienty je vždy nula, až na derivaci koeficientu svou derivací, ta je 1.\n",
    "\n",
    "The correct motivation for least squares is the Gaussian error model. The probability of error e goes like exp(-C e^2), and so the total probability density for all the errors is the product of these exponentials, or exp( - weighted sum of squares ). Minimizing the square deviation is the same as maximizing the probability of getting the data given your model. This is the Bayesian rule for finding the most likely possibility for the parameter values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokud začnu prokládat data namísto jedné křivky mnoha přímkami, získávám toto (algebraická a maticová forma):\\\n",
    "<img src=\"./picture_linearLeastSquares1.PNG\" alt=\"přímky algebraicky\"  width=\"200\"  height=\"150\"> \n",
    "<img src=\"./picture_linearLeastSquares2.PNG\" alt=\"přímky maticově\"  width=\"300\"  height=\"150\"> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Pokud začnu prokládat data namísto jedné křivky mnoha obecnými křivkami, získávám toto (algebraická a maticová forma):\\\n",
    "<img src=\"./picture_linearLeastSquares3.PNG\" alt=\"bázovka algebraicky\"  width=\"300\"  height=\"150\"> \n",
    "<img src=\"./picture_linearLeastSquares4.PNG\" alt=\"bázovka maticově\"  width=\"500\"  height=\"150\"> \\\n",
    "\n",
    "Maticová forma pěkně separuje bázové funkce a koeficienty.\\\n",
    "- Mám n řádků (n-bodů v datasetu)\n",
    "- Mám n+1 sloupečků (koeficienty číslujeme od 0)\n",
    "- linka má řád 1, takže má 2 parametry k řešení (k,q)\n",
    "\n",
    "Matici budeme nazývat X, protože závisí zcela na známých hodnotách x z datasetu, není možné, aby tam byly neznámé hodnoty\\\n",
    "Kompaktně matici můžeme zapsat jako $X\\vec{c} \\approx \\vec{y}$, tedy je to aproximace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalizovaný fit reziduí bude mít tvar: \\\n",
    "$\\vec{e} = \\vec{y} - X\\vec{c}$\\\n",
    "\n",
    "Potřebujeme pořád čtverec reziduí, proto obě strany rovnice vynásobíme transponovanou maticí reziduí\\\n",
    "$\\vec{e}^T \\vec{e} = \\vec{e} (\\vec{y} - X\\vec{c})$\\\n",
    "\n",
    "Definici generalizovaného fitu reziduí dosadíme opět do rovnice.\\\n",
    "$\\vec{e}^T (\\vec{y} - X\\vec{c}) = (\\vec{y} - X\\vec{c})^T (\\vec{y} - X\\vec{c})$\\\n",
    "\n",
    "Na levé straně vynásobením řádkového vektoru sloupcovým (vektor a jeho transpozice je skalární součin) čtverec jeho velikosti.\\\n",
    "${|\\vec{e}|}^2 = (\\vec{y} - X\\vec{c})^T (\\vec{y} - X\\vec{c})$\n",
    "\n",
    "Transpoziční člen na pravé straně rozdistribuuji.\\\n",
    "${|\\vec{e}|}^2 = (\\vec{y}^T - \\vec{c}^TX^T) (\\vec{y} - X\\vec{c})$\n",
    "\n",
    "\\\n",
    "\\\n",
    "\\\n",
    ".\n",
    "\n",
    "A rovnici roznásobím:\\\n",
    "Získávám SSRE generalizované metody lineárních nejmenších čtverců\\\n",
    "${|\\vec{e}|}^2 = \\vec{y}^T\\vec{y} - \\vec{y}^TX\\vec{c} - \\vec{c}^TX^T\\vec{y} + \\vec{c}^TX^TX\\vec{c}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "\\\n",
    "\\\n",
    "Tuto funkci teď budeme minimalizovat.\\\n",
    "$\\frac{\\partial {|\\vec{e}|^2}}{\\partial{\\vec{c}}} =  \\frac{\\partial}{\\partial{\\vec{c}}} (\\vec{y}^T\\vec{y} - \\vec{y}^TX\\vec{c} - \\vec{c}^TX^T\\vec{y} + \\vec{c}^TX^TX\\vec{c})$ \\\n",
    "\n",
    "\n",
    "$\\frac{\\partial}{\\partial{\\vec{c}}} (\\vec{y}^T\\vec{y} - \\vec{y}^TX\\vec{c} - \\vec{c}^TX^T\\vec{y} + \\vec{c}^TX^TX\\vec{c}) = 0 $ \n",
    "\\je tam hnusná algebra, kterou nebudu dělat\\\n",
    "\n",
    "získávám:\\\n",
    "$X^TX\\vec{c} = X^T\\vec{y}$\n",
    "\n",
    "Matice dělit nemohu, ale mohu násobit její levou stranu inverzní maticí a tím získat vektor c.\\\n",
    "$\\vec{c} = X^{-T}X^T\\vec{y}$\\\n",
    "$\\vec{c} = (X^{T}X)^{-1}\\vec{y}$ ... to $(X^{T}X)^{-1}$ se nazývá levé pseudo-prohození (left pseudo inverse)\\\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "\\\n",
    "\n",
    "Gaussovské normální rozdělení závislé proměnné y má následující tvar (velmi nelineární a ani to není lineární kombinací bázových funkcí)\\\n",
    "$y = \\frac{A}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "\\Můžeme to ale zkusit logaritmovat.\\\n",
    "$ln(y) = ln(\\frac{A}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}})$\\\n",
    "$ln(y) = ln(\\frac{A}{\\sigma\\sqrt{2\\pi}}) - \\frac{\\mu^2}{2\\sigma^2}  + \\frac{\\mu}{\\sigma^2}x - \\frac{1}{2\\sigma^2}x^2 $\n",
    "\\\n",
    "\\\n",
    "\n",
    "Tím jsme separovali své parametry od dat a teď to můžeme převést do lingebře přátelské formy.\\\n",
    "$c_0 = ln(\\frac{A}{\\sigma\\sqrt{2\\pi}}) - \\frac{\\mu^2}{2\\sigma^2}$\\\n",
    "$c_1 = \\frac{\\mu}{\\sigma^2}$\\\n",
    "$c_2 = - \\frac{1}{2\\sigma^2}x^2$\n",
    "\n",
    "$ln(y) = c_0 + c_1x + c_2x^2$\\\n",
    "\\\n",
    "\n",
    "Nebo taky maticově:\n",
    "\n",
    "<img src=\"./picture_linearLeastSquares5_.PNG\" alt=\"koeficienty gaussova rozdělení LSM\"  width=\"500\"  height=\"200\"> \\\n",
    "$X\\vec{c} = \\vec{y}$\n",
    "\\\n",
    "<img src=\"./picture_linearLeastSquares6.PNG\" alt=\"koeficienty gaussova rozdělení LSM\"  width=\"250\"  height=\"150\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Představme si, že máme polovodič a získáme jeho kapacitanci v závislosti na namětí z tabulky. Ta je ale dost nelineární.\\\n",
    "<img src=\"./picture_linearLeastSquares7.PNG\" alt=\"C = f(U)\"  width=\"250\"  height=\"150\">\\\n",
    "\n",
    "Vztah, který použijeme, je:\n",
    "\n",
    "$C(U) = \\frac{C_j}{(V_b + U)^\\gamma}$\n",
    "- U... externí aplikované napětí\n",
    "- Vb... konstanta (bariérový potenciál)\n",
    "- Cj, gamma... neznámé parametry\n",
    "\n",
    "\n",
    "\n",
    "Úpravou získáme separovaný vztah, na nějž lze metodu aplikovat.\\\n",
    "$lnC(U) = lnC_j - \\gamma ln(V_b + U)$\n",
    "\n",
    "Převedeno do matice:\\\n",
    "<img src=\"./picture_linearLeastSquares8.PNG\" alt=\"koeficienty gaussova rozdělení LSM kapacitance\"  width=\"300\"  height=\"150\">\n",
    "\n",
    "Použitím levé pseudoinverze dostáváme řešitelný tvar:\\\n",
    "<img src=\"./picture_linearLeastSquares9.PNG\" alt=\"koeficienty gaussova rozdělení LSM kapacitance\"  width=\"300\"  height=\"100\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66.59]]\n",
      "[[0.01501727]]\n",
      "[[0.01501727]\n",
      " [0.03003454]\n",
      " [0.03303799]\n",
      " [0.04655354]\n",
      " [0.04955699]\n",
      " [0.06006908]\n",
      " [0.06757771]] \n",
      "\n",
      "[[6.03844421]]\n"
     ]
    }
   ],
   "source": [
    "#zde je X U\n",
    "import numpy as np\n",
    "\n",
    "U: list[float] = np.matrix([1.0, 2.0, 2.2, 3.1, 3.3, 4.0, 4.5])\n",
    "C: list[float] = np.matrix([72., 35.0, 30.0, 20.0, 17.0, 10., 8.0])\n",
    "\n",
    "X_TX = U*U.T\n",
    "X_TXI = X_TX.I\n",
    "X_TXIX_T = U.T*X_TXI\n",
    "result = C*X_TXIX_T\n",
    "\n",
    "print(X_TX)\n",
    "print(X_TXI)\n",
    "print(X_TXIX_T, \"\\n\")\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
